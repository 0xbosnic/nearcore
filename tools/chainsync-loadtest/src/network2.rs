use std::collections::{HashSet,HashMap};
use std::io;
use std::pin::{Pin};
use std::sync::{Arc};
use std::sync::atomic::{AtomicU64,Ordering};
use std::future::Future;

use parking_lot::{Mutex};
use futures::future::{BoxFuture,FutureExt};
use bytes::{BytesMut,BufMut};
use bytesize::{GIB, MIB};
use borsh::{BorshDeserialize, BorshSerialize};
use tokio_util::codec::{Decoder,Encoder};
use tracing::metadata;
use tracing::{info};
use clap::{Clap};
use tokio::time;
use tokio::net;
use tokio::sync::{Semaphore};
use tokio::io::{AsyncReadExt,AsyncWriteExt,AsyncRead,AsyncWrite,BufStream};
use anyhow::{anyhow,Context};

use nearcore::config::{NearConfig};
use near_network_primitives::types::{PeerInfo,PartialEdgeInfo,PeerChainInfoV2};
use near_primitives::network::{PeerId};
use near_primitives::version::{PEER_MIN_ALLOWED_PROTOCOL_VERSION,PROTOCOL_VERSION};
use crate::peer_manager::peer::codec::{Codec};
use crate::peer_manager::types::{PeerMessage,Handshake};
use crate::concurrency::{Ctx,Scope};

struct Stream<RW>(BufStream<RW>);

impl<RW:AsyncRead+AsyncWrite+Unpin> Stream<RW> {
    fn new(rw:RW) -> Self { Self(BufStream::new(rw)) }
    
    async fn read(&mut self, ctx: &Ctx) -> anyhow::Result<PeerMessage> {
        let n = ctx.wrap(self.0.read_u32_le()).await?? as usize;
		// TODO: if this check fails, the stream is broken, because we read some bytes already.
		if n>NETWORK_MESSAGE_MAX_SIZE_BYTES { return Err(anyhow!("message size too large")); }
        let mut buf = BytesMut::new();
	    buf.resize(n,0);	
        ctx.wrap(self.0.read_exact(&mut buf[..])).await??;
        Ok(PeerMessage::try_from_slice(&buf[..])?)
    }
    
    async fn write(&mut self, ctx: &Ctx, msg: &PeerMessage) -> anyhow::Result<()> {
        let msg = msg.try_to_vec()?;
        // TODO: If writing fails in the middle, then the stream is broken.
        ctx.wrap(self.0.write_u32_le(msg.len() as u32)).await??;
        ctx.wrap(self.0.write_all(&msg[..])).await??;
        ctx.wrap(self.0.flush()).await??;
        Ok(())
    } 
}

trait NodeServer {
    // Here is the interface that a node should expose to the network.
}

struct MustComplete<F>{
    f:F,
    completed:bool,
}

// Async functions running to completion RFC:
// https://github.com/Matthias247/rfcs/pull/1

// https://carllerche.com/2021/06/17/six-ways-to-make-async-rust-easier/
// http://aidancully.blogspot.com/2021/12/linear-types-can-help.html
// https://gankra.github.io/blah/linear-rust/
// https://github.com/rust-lang/rfcs/issues/814

// TODO: this is still incomplete, since you may wrap an already completed future
// and it will panic.
impl<'a,F,R> Future for MustComplete where
    F:Future<Output=R>+'a
{
    type Output = R;
    fn poll(self:Pin<&mut Self>, cx: &mut Context<'_>) -> Poll<Self::Output> {
        let r = self.f.poll(cx);
        if r.is_ready(){ self.completed = true; }
        return r;
    }
}

trait MustCompleteExt {
    fn must_complete(self) -> MustComplete<Self>;
}

impl<F:Future> MustCompleteExt for F {
    fn must_complete(self) -> MustComlete<Self> {
        MustComplete{f:self,completed:false},
    }
}

// TODO: add a macro for wrapping "async fn <name>(...) -> ...".


// This should be a stream wrapper which exposes async interface (should be autogenerated).
// You MAY want to turn it into an interface given
struct NodeClient { // TODO: this is more like NodeConn, splitting streams would take more effort.
    // TODO: these methods have to make sure that they are not waiting on a closed connection.
    async fn fetch_block(Arc<self>,&Ctx,hash) -> anyhow::Result<Vec<BlockHeader>>;
    async fn fetch_block_headers();
    async fn fetch_chunk();
    fn new(stream) -> NodeClient;
    stream : Stream
    
    async fn event_loop(&self, &dyn NodeServer) -> anyhow::Result<()> {

    }

    // private
    // TODO: these can be regular HashMaps, if we can force the RPC call futures to
    // be never dropped incomplete. This is a property that would be awesome to have statically
    // checked.
    block_headers: Arc<WeakMap<CryptoHash, Once<anyhow::Result<Vec<BlockHeader>>>>>,
    blocks: Arc<WeakMap<CryptoHash, Once<anyhow::Result<Block>>>>,
    chunks: Arc<WeakMap<ChunkHash, Once<anyhow::Result<PartialEncodedChunkResponseMsg>>>>,

    // separate for each connection, for client part (QPS limit)
    rate_limiter 
    // shared across all connections, for server part (max inflight, perhaps distinguish costs)
    // TODO: consider moving to NodeServer itself.
    Arc<Throttler> 
}

// In fact, this is OUTBOUND peer connection,
// TODO: support for INBOUND peer connections.
struct PeerConn {
    
    stream: // sth to write to.
}

impl NodeClient {

    fn event_loop(&self,&Ctx,&dyn NodeServer) {
        let stream = ctx.wrap(net::TcpStream::connect(addr)).await.context("connect()")??;
        let mut stream = Stream::new(stream);
        let my_peer_id = PeerId::new(cfg.network_config.public_key.clone());
        let my_addr = cfg.network_config.addr.unwrap_or(stream.local_addr()?);
        let edge_info = PartialEdgeInfo::new(&my_peer_id, &peer_info.id, 1, &cfg.network_config.secret_key);
        
        let genesis_id = crate::config::genesis_id(&cfg.client_config.chain_id); 
        let msg = PeerMessage::Handshake(Handshake::new(
            PROTOCOL_VERSION, // TODO: check when exactly the handshake fails on protocol mismatch
            my_peer_id.clone(),
            peer_info.id.clone(),
            Some(my_addr.port()), // required 
            PeerChainInfoV2 {
                genesis_id: genesis_id.clone(), 
                height: 0,
                tracked_shards: Default::default(),
                archival: false,
            },
            edge_info,
        ));
        let mut stream = Stream::new(stream);
        stream.write(ctx,&msg).await.context("stream.write(Handshake)")?;
        if let PeerMessage::Handshake(h) = stream.read(ctx).await.context("stream.read(Handshake)")? {
            
        } else {
            // error (or loop until handshake)
        }
       
        loop {
            // event loop
            // + monitoring of the peer responsiveness.
        }
        // TODO: graceful disconnect message?
    }
}

struct PeerManager {
    peers : HashMap<PeerId,ConcreteClient>,
    // Obtains a list of PeerInfos, that we managed to perform a handshake with.
    //
    // maintain a pool of connections of size at least n
    // that is good enough: last x requests have latency at most M at y%.
    // spawn new connection otherwise.
}

impl PeerManager {
    async fn any_peer() -> Arc<NodeClient> {
    }

    async fn run(&self,ctx,server) -> anyhow::Result<()> {
        Scope::run(ctx,|ctx,s|{
            Semaphore want_conn;
            loop {
                let permit = ctx.wrap(want_conn.acquire()).await?;
                s.spawn_weak(||async move{
                    let permit = permit;
                    let stream = Stream::new(TcpStream::connect(next_peer_info.addr).await?);
                    let client = NodeClient::new(stream);
                    pm.clients.insert(client);
                    let err = client.event_loop(ctx,server).await;
                    pm.clients.erase(client);
                    // TODO: ignore/log only expected errors.
                    Ok(())
                });
            }
        });
    }
}
